{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "url = 'https://s3-eu-west-1.amazonaws.com/dwh-test-resources/recipes.json'\n",
    "\n",
    "r = requests.get(url=url)\n",
    "data = r.text\n",
    "parsed_recipes = data.replace('\\n{\"name\"', ',\\n{\"name\"')\n",
    "recipes = json.loads(\"[\" + parsed_recipes + \"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(duration):\n",
    "    \"\"\" Parses time from JSON file to minutes\n",
    "    -----------------------------------------\n",
    "    Uses regex expresion to get numbers and \n",
    "    their positions. If the number is in the \n",
    "    position of hours, it's multuplied by 60.\n",
    "    If it's in the position of minutes, it \n",
    "    stays the same.\n",
    "    If the field is empty, it returns 0 minutes.\n",
    "\n",
    "    Arguments:\n",
    "    duration -- content of JSON file for duration\n",
    "    field in the format (PTxHxM)\n",
    "    \"\"\"\n",
    "    time_regex = re.compile('[A-Z]')\n",
    "    time_values = time_regex.split(duration)\n",
    "    time_values = list(filter(None, time_values))\n",
    "    items = len(time_values)\n",
    "    if items == 2:\n",
    "        return int(time_values[0])*60 + int(time_values[1])\n",
    "    elif items == 1:\n",
    "        return int(time_values[0])\n",
    "    return 0\n",
    "  \n",
    "def get_level(prep_time):\n",
    "    \"\"\" Return complexity level for each\n",
    "    recipe.\n",
    "    ------------------------------------\n",
    "    Using the following rules:\n",
    "    Easy: total preparation time less than \n",
    "    30 minutes\n",
    "    Medium: Total prepatarion time between\n",
    "    30 minutes and an hour. \n",
    "    Hard: Total preparation time greater \n",
    "    than an hour.\n",
    "\n",
    "    Please note that recipes with duration \n",
    "    of 0 minutes will not be classified.\n",
    "\n",
    "    Arguments:\n",
    "    prep_time -- total preparation time in\n",
    "    minutes.\n",
    "    \"\"\"\n",
    "\n",
    "    if prep_time < 30 and prep_time > 0:\n",
    "        return 'easy'\n",
    "    elif prep_time >=30 and prep_time < 60:\n",
    "        return 'medium'\n",
    "    return 'hard'\n",
    "\n",
    "def map_tuples(x):\n",
    "    \"\"\" Returns a tuple with the following format\n",
    "    (level, (total_preparation_time, 1))\n",
    "    ---------------------------------------------\n",
    "\n",
    "    The selected format is necessary in order to use\n",
    "    the reduceByKey function and returning total \n",
    "    time and the amount of recipes per level.\n",
    "\n",
    "    Arguments:\n",
    "    x -- input rows of rdd\n",
    "    \"\"\"\n",
    "    return (x[6], (x[5], 1))\n",
    "\n",
    "def count_times(a, b):\n",
    "    \"\"\" Returns grouped levels with corresponding\n",
    "    times and number of recipes.\n",
    "    ----------------------------------------------\n",
    "\n",
    "    Arguments:\n",
    "    a -- Grouped data of previous rows\n",
    "    b -- Current row of rdd\n",
    "    \"\"\"\n",
    "    return (a[0] + b[0], a[1] + b[1])\n",
    "\n",
    "def get_averages(x):\n",
    "    \"\"\" Returns the average for each level\n",
    "    by dividing the values of the tuple returned.\n",
    "    ----------------------------------------------\n",
    "\n",
    "    Arguments:\n",
    "    x -- current row of rdd\n",
    "    \"\"\"\n",
    "    return (x[0], x[1][0]/x[1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "def create_recipes_rdd():\n",
    "    \"\"\" Creates an RDD of recipes with necessary data.\n",
    "    --------------------------------------------------\n",
    "    \n",
    "    For the purpose of the challenge some columns were\n",
    "    ommited from the RDD.\n",
    "    \"\"\"\n",
    "\n",
    "    recipes_rows = []\n",
    "    for index, recipe in enumerate(recipes):\n",
    "        recipe_name = recipe['name']\n",
    "        ingredients = recipe['ingredients']\n",
    "        prep_time = get_duration(recipe['prepTime'])\n",
    "        cook_time = get_duration(recipe['cookTime'])\n",
    "        total_prep_time = prep_time + cook_time\n",
    "        level=get_level(total_prep_time)\n",
    "        recipes_rows.append((index, recipe_name, ingredients, prep_time, cook_time, total_prep_time, level))\n",
    "    return sc.parallelize(recipes_rows)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "recipes_rdd = create_recipes_rdd()\n",
    "\n",
    "# Uses RDD to process data\n",
    "recipes_with_beef = recipes_rdd\\\n",
    "                            .filter(lambda x: 'beef' in x[2].lower())\n",
    "average_times = recipes_rdd\\\n",
    "                            .map(map_tuples)\\\n",
    "                            .reduceByKey(count_times)\\\n",
    "                            .map(get_averages)\n",
    "\n",
    "# Create column names for CSV files\n",
    "beef_recipes_columns = ['id', 'name', 'ingredients', 'prepTime', 'cookTime', 'totalPrepTime', 'level']\n",
    "average_columns = ['difficulty', 'avg_total_cooking_time']\n",
    "\n",
    "# Convert RDDs into DF in order to prepare CSV writing\n",
    "beef_recipes_df = recipes_with_beef.toDF(beef_recipes_columns)\n",
    "average_times_df = average_times.toDF(average_columns)\n",
    "\n",
    "# Write into CSV files\n",
    "beef_recipes_df.repartition(1).write.csv('beef', header=True)\n",
    "average_times_df.repartition(1).write.csv('output', header=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}